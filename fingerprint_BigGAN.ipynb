{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "fingerprint_BigGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbEW1V9etTtY",
        "colab_type": "text"
      },
      "source": [
        "# Fingerprint BigGAN\n",
        "Based on [this kaggle kernel](https://www.kaggle.com/yukia18/sub-rals-ac-biggan-with-minibatchstddev). [Model description](https://www.kaggle.com/c/generative-dog-images/discussion/104211#latest-601531)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoDhE2esx5Ig",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDeG1Z44yLJG",
        "colab_type": "text"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/Luksalos/BIO-fingerprint-GAN/blob/master/fingerprint_BigGAN.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/Luksalos/BIO-fingerprint-GAN/blob/master/fingerprint_BigGAN.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "13dGjbBW3tha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import random\n",
        "import glob\n",
        "import shutil\n",
        "import warnings\n",
        "\n",
        "import cv2\n",
        "import scipy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "import xml.etree.ElementTree as ET\n",
        "import albumentations as A\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from PIL import Image\n",
        "from albumentations.pytorch import ToTensor\n",
        "from tqdm import tqdm_notebook, trange\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils import spectral_norm\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.utils import make_grid, save_image\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dL_uVVAm6-i0",
        "colab_type": "code",
        "outputId": "02233556-7672-418d-9f0c-07e95ec61687",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2zZnnLS95tD",
        "colab_type": "text"
      },
      "source": [
        "**Kaggle versions:**               \n",
        "torch                              1.3.0                \n",
        "torchtext                          0.4.0               \n",
        "torchvision                        0.4.1a0+d94043a "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f6DKip48Cxx",
        "colab_type": "code",
        "outputId": "3b0d90e6-9ebd-4cfa-e1a9-7e46ee36a0fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "pip list | grep torch"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch                    1.3.1      \n",
            "torchsummary             1.5.1      \n",
            "torchtext                0.3.1      \n",
            "torchvision              0.4.2      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "collapsed": true,
        "id": "V85Omft53the",
        "colab_type": "text"
      },
      "source": [
        "# Settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIvmL1b23thf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = {\n",
        "    'DataLoader': {\n",
        "        'batch_size': 128,\n",
        "        'shuffle': True,\n",
        "    },\n",
        "    'Generator': {\n",
        "        'latent_dim': 120,\n",
        "        'embed_dim': 32,\n",
        "        'ch': 64,\n",
        "        'num_classes': 120,\n",
        "        'use_attn': True,\n",
        "    },\n",
        "    'Discriminator': {\n",
        "        'ch': 64,\n",
        "        'num_classes': 120,\n",
        "        'use_attn': True,\n",
        "    },\n",
        "    'sample_latents': {\n",
        "        'latent_dim': 120,\n",
        "        'num_classes': 120,\n",
        "    },\n",
        "    'num_iterations': 10000,\n",
        "    'decay_start_iteration': 25000,\n",
        "    'd_steps': 1,\n",
        "    'lr_G': 2e-4,\n",
        "    'lr_D': 4e-4,\n",
        "    'betas': (0.0, 0.999),\n",
        "    'margin': 1.0,\n",
        "    'gamma': 0.1,\n",
        "    'ema': 0.999,\n",
        "    'seed': 42,\n",
        "    'fresh_start': False,\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SeOXShP3thi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "seed_everything(config['seed'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xx38_gYgNYvJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if config['fresh_start']:\n",
        "    for f in glob.glob('gen/*'):\n",
        "        os.unlink(f)\n",
        "    for n in glob.glob('net*.pt'):\n",
        "        os.unlink(n)\n",
        "\n",
        "if not os.path.exists(\"gen/\"):\n",
        "    os.mkdir(\"gen/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USu-E8Abt8sc",
        "colab_type": "text"
      },
      "source": [
        "# Get data\n",
        "TODO\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xea_p3VKeQY2",
        "colab_type": "text"
      },
      "source": [
        "### Mount Google drive and unzip files \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfpom1-TXvR9",
        "colab_type": "code",
        "outputId": "524130c7-5381-422b-a281-af7756b2bda1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJNY3pWyeBqs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists('/content/SOCOFing/'):\n",
        "    %%capture\n",
        "    !unzip 'drive/My Drive/MIT/BIO/SOCOFing.zip' -d '/content/SOCOFing/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZefqzmBQ3thk",
        "colab_type": "text"
      },
      "source": [
        "# Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efo0XkKR3thm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root_images = '/content/SOCOFing/Real/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kGHuwQx3thp",
        "colab_type": "code",
        "outputId": "94956b21-21ab-4a03-a07c-c21b7ebfbe1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "all_files = os.listdir(root_images)\n",
        "print(all_files[:5])"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['52__M_Right_thumb_finger.BMP', '254__M_Left_index_finger.BMP', '505__M_Left_middle_finger.BMP', '328__M_Right_middle_finger.BMP', '79__M_Right_index_finger.BMP']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0guHXh283th8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_image(file):\n",
        "    img = cv2.imread(os.path.join(root_images, file))\n",
        "    transform = A.Compose([A.Resize(64, 64, interpolation=cv2.INTER_AREA),\n",
        "                           A.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "    return transform(image=img)['image']\n",
        "\n",
        "all_images = [load_image(f) for f in all_files]\n",
        "all_images = np.array(all_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeJVchy9Iem5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f0356f6b-2158-4b06-a69b-272b3e58ee5e"
      },
      "source": [
        "def extract_label(file):\n",
        "    _, label = file.split('__', 1)\n",
        "    label, _ = label.split('.', 1)\n",
        "    return label\n",
        "\n",
        "all_labels = [extract_label(f) for f in all_files]\n",
        "all_labels = LabelEncoder().fit_transform(all_labels)\n",
        "print(all_labels[:5])"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[19 10 12 17 15]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eHwg_WF3tiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FingerprintDataset(Dataset):\n",
        "    def __init__(self, images, labels):\n",
        "        super().__init__()\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transform = A.Compose([A.HorizontalFlip(p=0.5), ToTensor()])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, label = self.images[idx], self.labels[idx]\n",
        "        img = self.transform(image=img)['image']\n",
        "        label = torch.as_tensor(label, dtype=torch.long)\n",
        "\n",
        "        return img, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "234GdYw73tiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# adding uniform noise works well.\n",
        "\n",
        "def get_dataiterator(images, labels, dataloader_params, device='cpu'):\n",
        "    train_dataset = FingerprintDataset(images, labels)\n",
        "    train_dataloader = DataLoader(train_dataset, **dataloader_params)\n",
        "    batch_size = dataloader_params['batch_size']\n",
        "\n",
        "    while True:\n",
        "        for imgs, labels in train_dataloader:\n",
        "            if batch_size != imgs.size(0):\n",
        "                break\n",
        "            else:\n",
        "                imgs, labels = imgs.to(device), labels.to(device)\n",
        "                imgs += (1.0 / 128.0) * torch.rand_like(imgs)\n",
        "\n",
        "                yield imgs, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-k1COhhe3tiG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# batch size around 64 ~ 128 improves score.\n",
        "# ~ 64 are too small, 128 ~ are too large (for 9 hours training). \n",
        "\n",
        "train_dataiterator = get_dataiterator(all_images, all_labels, config['DataLoader'], device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4CiCkom3tiJ",
        "colab_type": "text"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aacb_lN23tiK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Attention slightly works.\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, channels, reduction_attn=8, reduction_sc=2):\n",
        "        super().__init__()\n",
        "        self.channles_attn = channels // reduction_attn\n",
        "        self.channels_sc = channels // reduction_sc\n",
        "        \n",
        "        self.conv_query = spectral_norm(nn.Conv2d(channels, self.channles_attn, kernel_size=1, bias=False))\n",
        "        self.conv_key = spectral_norm(nn.Conv2d(channels, self.channles_attn, kernel_size=1, bias=False))\n",
        "        self.conv_value = spectral_norm(nn.Conv2d(channels, self.channels_sc, kernel_size=1, bias=False))\n",
        "        self.conv_attn = spectral_norm(nn.Conv2d(self.channels_sc, channels, kernel_size=1, bias=False))\n",
        "        self.gamma = nn.Parameter(torch.zeros(1))\n",
        "        \n",
        "        nn.init.orthogonal_(self.conv_query.weight.data)\n",
        "        nn.init.orthogonal_(self.conv_key.weight.data)\n",
        "        nn.init.orthogonal_(self.conv_value.weight.data)\n",
        "        nn.init.orthogonal_(self.conv_attn.weight.data)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch, _, h, w = x.size()\n",
        "        \n",
        "        proj_query = self.conv_query(x).view(batch, self.channles_attn, -1)\n",
        "        proj_key = F.max_pool2d(self.conv_key(x), 2).view(batch, self.channles_attn, -1)\n",
        "        \n",
        "        attn = torch.bmm(proj_key.permute(0,2,1), proj_query)\n",
        "        attn = F.softmax(attn, dim=1)\n",
        "        \n",
        "        proj_value = F.max_pool2d(self.conv_value(x), 2).view(batch, self.channels_sc, -1)\n",
        "        attn = torch.bmm(proj_value, attn)\n",
        "        attn = attn.view(batch, self.channels_sc, h, w)\n",
        "        attn = self.conv_attn(attn)\n",
        "        \n",
        "        out = self.gamma * attn + x\n",
        "        \n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYcNw3E53tiM",
        "colab_type": "text"
      },
      "source": [
        "## Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PLNeKm93tiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# using label information works well.\n",
        "# As for generator, it is realized by conditional batch normalization.\n",
        "\n",
        "class CBN2d(nn.Module):\n",
        "    def __init__(self, num_features, num_conditions):\n",
        "        super().__init__()\n",
        "        self.bn = nn.BatchNorm2d(num_features, affine=False)\n",
        "        self.embed = spectral_norm(nn.Conv2d(num_conditions, num_features*2, kernel_size=1, bias=False))\n",
        "        \n",
        "        nn.init.orthogonal_(self.embed.weight.data)\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        out = self.bn(x)\n",
        "        embed = self.embed(y.unsqueeze(2).unsqueeze(3))\n",
        "        gamma, beta = embed.chunk(2, dim=1)\n",
        "        out = (1.0 + gamma) * out + beta \n",
        "\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSWEBcvL3tiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# residual block improves convergence speed and generated image's quality.\n",
        "# nearest upsampling is better than others.\n",
        "\n",
        "class GBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_conditions, upsample=False):\n",
        "        super().__init__()\n",
        "        self.upsample = upsample\n",
        "        self.learnable_sc = in_channels != out_channels or upsample\n",
        "        \n",
        "        self.conv1 = spectral_norm(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False))\n",
        "        self.conv2 = spectral_norm(nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False))\n",
        "        self.cbn1 = CBN2d(in_channels, num_conditions)\n",
        "        self.cbn2 = CBN2d(out_channels, num_conditions)\n",
        "        if self.learnable_sc:\n",
        "            self.conv_sc = spectral_norm(nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False))\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        nn.init.orthogonal_(self.conv1.weight.data)\n",
        "        nn.init.orthogonal_(self.conv2.weight.data)\n",
        "        if self.learnable_sc:\n",
        "            nn.init.orthogonal_(self.conv_sc.weight.data)\n",
        "    \n",
        "    def _upsample_conv(self, x, conv):\n",
        "        x = F.interpolate(x, scale_factor=2, mode='nearest')\n",
        "        x = conv(x)\n",
        "        \n",
        "        return x\n",
        "    \n",
        "    def _residual(self, x, y):\n",
        "        x = self.relu(self.cbn1(x, y))\n",
        "        x = self._upsample_conv(x, self.conv1) if self.upsample else self.conv1(x)\n",
        "        x = self.relu(self.cbn2(x, y))\n",
        "        x = self.conv2(x)\n",
        "        \n",
        "        return x\n",
        "    \n",
        "    def _shortcut(self, x):\n",
        "        if self.learnable_sc:\n",
        "            x = self._upsample_conv(x, self.conv_sc) if self.upsample else self.conv_sc(x)\n",
        "            \n",
        "        return x\n",
        "    \n",
        "    def forward(self, x, y):\n",
        "        return self._shortcut(x) + self._residual(x, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPBELHdd3tiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# shared embedding of class labels, and hierarchical latent noise, work well.\n",
        "# this architecture is the same as BigGAN except for channel size.\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim, ch, num_classes, embed_dim, use_attn=False):\n",
        "        super().__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.ch = ch\n",
        "        self.num_classes = num_classes\n",
        "        self.embed_dim = embed_dim\n",
        "        self.use_attn = use_attn\n",
        "        self.num_chunk = 5\n",
        "        num_latents = self.__get_num_latents()\n",
        "        \n",
        "        self.embed = nn.Embedding(num_classes, embed_dim)\n",
        "        self.fc = spectral_norm(nn.Linear(num_latents[0], ch*8*4*4, bias=False))\n",
        "        self.block1 = GBlock(ch*8, ch*8, num_latents[1], upsample=True)\n",
        "        self.block2 = GBlock(ch*8, ch*4, num_latents[2], upsample=True)\n",
        "        self.block3 = GBlock(ch*4, ch*2, num_latents[3], upsample=True)\n",
        "        if use_attn:\n",
        "            self.attn = Attention(ch*2)\n",
        "        self.block4 = GBlock(ch*2, ch, num_latents[4], upsample=True)\n",
        "        self.bn = nn.BatchNorm2d(ch)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv_last = spectral_norm(nn.Conv2d(ch, 3, kernel_size=3, padding=1, bias=False))\n",
        "        self.tanh = nn.Tanh()\n",
        "        \n",
        "        nn.init.orthogonal_(self.embed.weight.data)\n",
        "        nn.init.orthogonal_(self.fc.weight.data)\n",
        "        nn.init.orthogonal_(self.conv_last.weight.data)\n",
        "        nn.init.constant_(self.bn.weight.data, 1.0)\n",
        "        nn.init.constant_(self.bn.bias.data, 0.0)\n",
        "    \n",
        "    def __get_num_latents(self):\n",
        "        xs = torch.empty(self.latent_dim).chunk(self.num_chunk)\n",
        "        num_latents = [x.size(0) for x in xs]\n",
        "        for i in range(1, self.num_chunk):\n",
        "            num_latents[i] += self.embed_dim\n",
        "        \n",
        "        return num_latents\n",
        "    \n",
        "    def forward(self, x, y):\n",
        "        xs = x.chunk(self.num_chunk, dim=1)\n",
        "        y = self.embed(y)\n",
        "        \n",
        "        h = self.fc(xs[0])\n",
        "        h = h.view(h.size(0), self.ch*8, 4, 4)\n",
        "        h = self.block1(h, torch.cat([y, xs[1]], dim=1))\n",
        "        h = self.block2(h, torch.cat([y, xs[2]], dim=1))\n",
        "        h = self.block3(h, torch.cat([y, xs[3]], dim=1))\n",
        "        if self.use_attn:\n",
        "            h = self.attn(h)\n",
        "        h = self.block4(h, torch.cat([y, xs[4]], dim=1))\n",
        "        h = self.relu(self.bn(h))\n",
        "        out = self.tanh(self.conv_last(h))\n",
        "        \n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLmv05yY3tiY",
        "colab_type": "text"
      },
      "source": [
        "## Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLh0glXD3tiY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# residual block improves convergence speed and generated image's quality.\n",
        "\n",
        "class DBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, downsample=False, optimized=False):\n",
        "        super().__init__()\n",
        "        self.downsample = downsample\n",
        "        self.optimized = optimized\n",
        "        self.learnable_sc = in_channels != out_channels or downsample\n",
        "        \n",
        "        self.conv1 = spectral_norm(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False))\n",
        "        self.conv2 = spectral_norm(nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False))\n",
        "        if self.learnable_sc:\n",
        "            self.conv_sc = spectral_norm(nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False))\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "        nn.init.orthogonal_(self.conv1.weight.data)\n",
        "        nn.init.orthogonal_(self.conv2.weight.data)\n",
        "        if self.learnable_sc:\n",
        "            nn.init.orthogonal_(self.conv_sc.weight.data)\n",
        "\n",
        "    def _residual(self, x):\n",
        "        if not self.optimized:\n",
        "            x = self.relu(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        if self.downsample:\n",
        "            x = F.avg_pool2d(x, 2)\n",
        "        \n",
        "        return x\n",
        "    \n",
        "    def _shortcut(self, x):\n",
        "        if self.learnable_sc:\n",
        "            if self.optimized:\n",
        "                x = self.conv_sc(F.avg_pool2d(x, 2)) if self.downsample else self.conv_sc(x)\n",
        "            else:\n",
        "                x = F.avg_pool2d(self.conv_sc(x), 2) if self.downsample else self.conv_sc(x)\n",
        "        \n",
        "        return x\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self._shortcut(x) + self._residual(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNwBrXUF3tib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this architecture is the altered version of BigGAN Discriminator.\n",
        "# <- using residual block, projection.\n",
        "\n",
        "# but those points are different from original.\n",
        "# - reduce channel size.\n",
        "# - reduce model depth (remove last residual block).\n",
        "# - add minibatch stddev.\n",
        "# - with auxiliary classifier (ACGAN).\n",
        "#   <- improve image's quality and stabilize training.\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ch, num_classes, use_attn=False):\n",
        "        super().__init__()\n",
        "        self.ch = ch\n",
        "        self.num_classes = num_classes\n",
        "        self.use_attn = use_attn\n",
        "        \n",
        "        self.block1 = DBlock(3, ch, downsample=True, optimized=True)\n",
        "        if use_attn:\n",
        "            self.attn = Attention(ch)\n",
        "        self.block2 = DBlock(ch, ch*2, downsample=True)\n",
        "        self.block3 = DBlock(ch*2, ch*4, downsample=True)\n",
        "        self.block4 = DBlock(ch*4, ch*8, downsample=True)\n",
        "        self.block5 = DBlock(ch*8+1, ch*8, downsample=False)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc = spectral_norm(nn.Linear(ch*8, 1, bias=False))\n",
        "        self.embed = spectral_norm(nn.Embedding(num_classes, ch*8))\n",
        "        self.clf = spectral_norm(nn.Linear(ch*8, num_classes, bias=False))\n",
        "        \n",
        "        nn.init.orthogonal_(self.fc.weight.data)\n",
        "        nn.init.orthogonal_(self.embed.weight.data)\n",
        "        nn.init.orthogonal_(self.clf.weight.data)\n",
        "    \n",
        "    def minibatch_stddev(self, x, group_size=4, eps=1e-8):\n",
        "        shape = x.size()\n",
        "        y = x.view(group_size, -1, shape[1], shape[2], shape[3])\n",
        "        y -= torch.mean(y, dim=0, keepdim=True)\n",
        "        y = torch.mean(y.pow(2), dim=0)\n",
        "        y = torch.sqrt(y + eps)\n",
        "        y = torch.mean(y, dim=[1,2,3], keepdim=True)\n",
        "        y = y.repeat(group_size, 1, shape[2], shape[3])\n",
        "\n",
        "        return torch.cat([x, y], dim=1)\n",
        "    \n",
        "    def forward(self, x, y):\n",
        "        h = self.block1(x)\n",
        "        if self.use_attn:\n",
        "            h = self.attn(h)\n",
        "        h = self.block2(h)\n",
        "        h = self.block3(h)\n",
        "        h = self.block4(h)\n",
        "        h = self.block5(self.minibatch_stddev(h))\n",
        "        h = self.relu(h)\n",
        "        h = torch.sum(h, dim=(2,3))\n",
        "        \n",
        "        out = self.fc(h)\n",
        "        out += torch.sum(self.embed(y)*h, dim=1, keepdim=True)\n",
        "        \n",
        "        ac = self.clf(h)\n",
        "        ac = F.log_softmax(ac, dim=1)\n",
        "        \n",
        "        return out, ac"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWzoPV643tie",
        "colab_type": "text"
      },
      "source": [
        "# Train GANs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LRrH9Oj3tif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "netG = Generator(**config['Generator']).to(device, torch.float32)\n",
        "netD = Discriminator(**config['Discriminator']).to(device, torch.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghV73j8592Vj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmJ7HzhJ3tih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Exponential moving average of generator weights works well.\n",
        "# Got error, when updating netGE buffers\n",
        "\n",
        "# netGE = Generator(**config['Generator']).to(device, torch.float32)\n",
        "# netGE.load_state_dict(netG.state_dict());"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AF1951T3tij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optim_G = Adam(params=netG.parameters(), lr=config['lr_G'], betas=config['betas'])\n",
        "optim_D = Adam(params=netD.parameters(), lr=config['lr_D'], betas=config['betas'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ODyBXdx3til",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decay_iter = config['num_iterations'] - config['decay_start_iteration']\n",
        "if decay_iter > 0:\n",
        "    lr_lambda_G = lambda x: (max(0,1-x/decay_iter))\n",
        "    lr_lambda_D = lambda x: (max(0,1-x/(decay_iter*config['d_steps'])))\n",
        "    lr_sche_G = LambdaLR(optim_G, lr_lambda=lr_lambda_G)\n",
        "    lr_sche_D = LambdaLR(optim_D, lr_lambda=lr_lambda_D)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGL0vv8c3tin",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_advloss_D(real, fake, margin=1.0):\n",
        "    loss_real = torch.mean((real - fake.mean() - margin) ** 2)\n",
        "    loss_fake = torch.mean((fake - real.mean() + margin) ** 2)\n",
        "    loss = (loss_real + loss_fake) / 2\n",
        "    \n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dFrRG2m3tiq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_advloss_G(real, fake, margin=1.0):\n",
        "    loss_real = torch.mean((real - fake.mean() + margin) ** 2)\n",
        "    loss_fake = torch.mean((fake - real.mean() - margin) ** 2)\n",
        "    loss = (loss_real + loss_fake) / 2\n",
        "    \n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMt5qr0H3tit",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# auxiliary classifier loss.\n",
        "# this loss weighted by gamma (0.1) is added to adversarial loss.\n",
        "# coefficient gamma is quite sensitive.\n",
        "\n",
        "criterion = nn.NLLLoss().to(device, torch.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmQrw4Fl3tiv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample_latents(batch_size, latent_dim, num_classes):\n",
        "    latents = torch.randn((batch_size, latent_dim), dtype=torch.float32, device=device)\n",
        "    labels = torch.randint(0, num_classes, size=(batch_size,), dtype=torch.long, device=device)\n",
        "    \n",
        "    return latents, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cyiqh4EXN14h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Only for testing\n",
        "# counter = 0\n",
        "# for buffer_G, buffer_GE in zip(netG.buffers(), netGE.buffers()):\n",
        "#     if counter == 8:\n",
        "#         print(buffer_G)\n",
        "#         print(buffer_GE.data.mul_(1).add_(0*buffer_G.data))\n",
        "#         print(buffer_G)\n",
        "#     print(counter)\n",
        "#     # buffer_GE.data.mul_(config['ema']).add_((1-config['ema'])*buffer_G.data)\n",
        "    \n",
        "#     counter += 1\n",
        "#     # buffer_GE.data.mul_(config['ema']).add_((1-config['ema'])*buffer_G.data)\n",
        "# counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I74KzRqh3tiy",
        "colab_type": "code",
        "outputId": "0d548408-3d33-4786-a697-10e1a555e405",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Determine the last step the model reached in some previous run.\n",
        "# This should handle two situations where an inconsistency could have occured\n",
        "# due to early termination of the run:\n",
        "#   * either the new model was stored for generator but not discriminator,\n",
        "#   * or the old model was deleted for generator but not discriminator.\n",
        "def step_number(netX_path):\n",
        "    return int(netX_path[5:][:-3])\n",
        "\n",
        "prev_netG = glob.glob('netG-*.pt')\n",
        "prev_netD = glob.glob('netD-*.pt')\n",
        "prev_step = 1\n",
        "if prev_netG and prev_netD:\n",
        "    prev_netG.sort()\n",
        "    prev_netD.sort()\n",
        "    print(prev_netG)\n",
        "    print(prev_netD)\n",
        "    oldest_netG = prev_netG[0]\n",
        "    oldest_netD = prev_netD[0]\n",
        "    oldest_netG_step = step_number(oldest_netG)\n",
        "    oldest_netD_step = step_number(oldest_netD)\n",
        "    if oldest_netD_step < oldest_netG_step:\n",
        "        oldest_netD = prev_netD[1]\n",
        "        oldest_netD_step = step_number(oldest_netD)\n",
        "    assert(oldest_netG_step == oldest_netD_step)\n",
        "    prev_step = oldest_netG_step\n",
        "    # Load the models from previous run.\n",
        "    netG.load_state_dict(torch.load(f'netG-{prev_step}.pt'))\n",
        "    netD.load_state_dict(torch.load(f'netD-{prev_step}.pt'))\n",
        "print(prev_step)\n",
        "\n",
        "\n",
        "# todo: figure out, why it keeps printing new lines\n",
        "for step in trange(prev_step, config['num_iterations'], initial=prev_step):\n",
        "    # Discriminator\n",
        "    for i in range(config['d_steps']):\n",
        "        for param in netD.parameters():\n",
        "            param.requires_grad_(True)\n",
        "    \n",
        "        optim_D.zero_grad()\n",
        "\n",
        "        real_imgs, real_labels = train_dataiterator.__next__()\n",
        "        batch_size = real_imgs.size(0)\n",
        "\n",
        "        latents, fake_labels = sample_latents(batch_size, **config['sample_latents'])\n",
        "        fake_imgs = netG(latents, fake_labels).detach()\n",
        "        \n",
        "        preds_real, preds_real_labels = netD(real_imgs, real_labels)\n",
        "        preds_fake, _ = netD(fake_imgs, fake_labels)\n",
        "\n",
        "        loss_D = calc_advloss_D(preds_real, preds_fake, config['margin'])\n",
        "        loss_D += config['gamma'] * criterion(preds_real_labels, real_labels)\n",
        "        loss_D.backward()\n",
        "        optim_D.step()\n",
        "        \n",
        "        if (decay_iter > 0) and (step > config['decay_start_iteration']):\n",
        "            lr_sche_D.step()\n",
        "\n",
        "    # Generator\n",
        "    for param in netD.parameters():\n",
        "        param.requires_grad_(False)\n",
        "\n",
        "    optim_G.zero_grad()\n",
        "    \n",
        "    real_imgs, real_labels = train_dataiterator.__next__()\n",
        "    batch_size = real_imgs.size(0)\n",
        "    \n",
        "    latents, fake_labels = sample_latents(batch_size, **config['sample_latents'])\n",
        "    fake_imgs = netG(latents, fake_labels)\n",
        "\n",
        "    preds_real, _ = netD(real_imgs, real_labels)\n",
        "    preds_fake, preds_fake_labels = netD(fake_imgs, fake_labels)\n",
        "\n",
        "    loss_G = calc_advloss_G(preds_real, preds_fake, config['margin'])\n",
        "    loss_G += config['gamma'] * criterion(preds_fake_labels, fake_labels)\n",
        "    loss_G.backward()\n",
        "    optim_G.step()\n",
        "    \n",
        "    if (decay_iter > 0) and (step > config['decay_start_iteration']):\n",
        "        lr_sche_G.step()\n",
        "\n",
        "    torch.save(netG.state_dict(), f\"netG-{step}.pt\")\n",
        "    torch.save(netD.state_dict(), f\"netD-{step}.pt\")\n",
        "\n",
        "    if os.path.exists(f\"netG-{step-1}.pt\"):\n",
        "      os.unlink(f\"netG-{step-1}.pt\")\n",
        "    if os.path.exists(f\"netD-{step-1}.pt\"):\n",
        "      os.unlink(f\"netD-{step-1}.pt\")\n",
        "\n",
        "    if step % 8 == 0:\n",
        "      img.imsave(f'gen/fingerprint-{step}.png', fake_imgs[0].cpu().detach()[0])\n",
        "\n",
        "    # Got this error: result type Float can't be cast to the desired output type Long\n",
        "    # Exponential Moving Average (EMA) - https://openreview.net/forum?id=SJgw_sRqFQ\n",
        "    # Update Generator Eval\n",
        "    # for param_G, param_GE in zip(netG.parameters(), netGE.parameters()):\n",
        "    #     param_GE.data.mul_(config['ema']).add_((1-config['ema'])*param_G.data)\n",
        "    # for buffer_G, buffer_GE in zip(netG.buffers(), netGE.buffers()):\n",
        "    #     buffer_GE.data.mul_(config['ema']).add_((1-config['ema'])*buffer_G.data)"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 34/9966 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['netG-34.pt']\n",
            "['netD-34.pt']\n",
            "34\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 35/9966 [00:01<4:00:11,  1.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 36/9966 [00:02<4:01:31,  1.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 37/9966 [00:04<3:58:13,  1.44s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 38/9966 [00:05<4:01:06,  1.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 39/9966 [00:07<3:58:18,  1.44s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 40/9966 [00:08<3:58:07,  1.44s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 41/9966 [00:10<4:01:50,  1.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 42/9966 [00:11<3:59:01,  1.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 43/9966 [00:13<4:03:26,  1.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 44/9966 [00:14<4:01:19,  1.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 45/9966 [00:16<4:05:59,  1.49s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 46/9966 [00:17<4:02:42,  1.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 47/9966 [00:18<4:02:08,  1.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 48/9966 [00:20<4:02:49,  1.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-136-423755f31828>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mlr_sche_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"netG-{step}.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"netD-{step}.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \"\"\"\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[0;34m(f, mode, body)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \"\"\"\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mserialized_storage_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0mserialized_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_should_read_directly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXTgF6cf3ti2",
        "colab_type": "text"
      },
      "source": [
        "# Generate Samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfbQEUxW3ti3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def truncated_normal(size, threshold=2.0, dtype=torch.float32, device='cpu'):\n",
        "    x = scipy.stats.truncnorm.rvs(-threshold, threshold, size=size)\n",
        "    x = torch.from_numpy(x).to(device, dtype)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3DC3L7e3ti5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_eval_samples(generator, batch_size, latent_dim, num_classes):\n",
        "    latents = truncated_normal((batch_size, latent_dim), dtype=torch.float32, device=device)\n",
        "    labels =  torch.randint(0, num_classes, size=(batch_size,), dtype=torch.long, device=device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        imgs = (generator(latents, labels) + 1) / 2\n",
        "    \n",
        "    return imgs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7vmanVJ3ti7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_submissions(generator, user_images_unzipped_path, latent_dim, num_classes):\n",
        "    if not os.path.exists(user_images_unzipped_path):\n",
        "        os.mkdir(user_images_unzipped_path)\n",
        "    \n",
        "    sample_batch_size = 50\n",
        "    num_samples = 10000\n",
        "    \n",
        "    for i in range(0, num_samples, sample_batch_size):\n",
        "        imgs = generate_eval_samples(generator, sample_batch_size, latent_dim, num_classes)\n",
        "        for j, img in enumerate(imgs):\n",
        "            save_image(img, os.path.join(user_images_unzipped_path, f'image_{i+j:05d}.png'))\n",
        "    \n",
        "    shutil.make_archive('images', 'zip', user_images_unzipped_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCt0eFAO3ti-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# user_images_unzipped_path = '../output_images'\n",
        "# make_submissions(netGE, user_images_unzipped_path, **config['sample_latents'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8YOyXYk3tjA",
        "colab_type": "text"
      },
      "source": [
        "# See some examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqevW5sq3tjA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "repeat_breeds = 5\n",
        "nrow = 15\n",
        "split_size = 50\n",
        "\n",
        "latent_dim = config['sample_latents']['latent_dim']\n",
        "num_classes = config['sample_latents']['num_classes']\n",
        "\n",
        "all_labels = torch.arange(num_classes, dtype=torch.long, device=device)\n",
        "all_labels = all_labels.repeat_interleave(repeat_breeds)\n",
        "labels_split = all_labels.split(split_size)\n",
        "\n",
        "imgs_list = []\n",
        "for labels in labels_split:\n",
        "    batch_size = labels.size(0)\n",
        "    latents = truncated_normal((batch_size, latent_dim), threshold=1.5, dtype=torch.float32, device=device)\n",
        "    with torch.no_grad():\n",
        "        # imgs = (netGE(latents, labels) + 1) / 2\n",
        "        imgs = (netG(latents, labels) + 1) / 2\n",
        "        imgs_list.append(imgs)\n",
        "    \n",
        "all_imgs = torch.cat(imgs_list, dim=0)\n",
        "all_imgs = make_grid(all_imgs, nrow=nrow, normalize=False)\n",
        "all_imgs = all_imgs.mul_(255).add_(0.5).clamp_(0, 255).permute(1, 2, 0).to('cpu', torch.uint8).numpy()\n",
        "\n",
        "plt.figure(figsize=(2*nrow, 2*(num_classes*repeat_breeds)//nrow))\n",
        "plt.imshow(all_imgs);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPA1_M8P3tjG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}